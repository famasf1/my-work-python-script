{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# read clipboard\n",
    "#option 1 : get the whole thing in clipboard, easier but doesn't work in remote env\n",
    "df = pd.read_clipboard(sep='\\t')\n",
    "#option 2 : get the whole thing from excel\n",
    "df_excel = pd.read_excel(rf\"C:\\Users\\jambo\\Downloads\\stockout_3months.xlsx\",sheet_name=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read clipboard\n",
    "\n",
    "my_df = df #df or df_excel\n",
    "\n",
    "data_concat = pd.DataFrame(df['Stock Out (ID)'] + \"-\" + df['Branch (ID)']).rename(columns={0 : 'PHYID'}, inplace=False)\n",
    "data_concat = data_concat['PHYID'].str.replace(\",\",\"\")\n",
    "\n",
    "data_cat = pd.concat([df,data_concat], axis=1)\n",
    "result = data_cat.set_index('PHYID').rename(columns={'Good/Bad' : 'Good | Bad'}, inplace=False)\n",
    "##need Booking ID, Stockout-ID, Branch ID,  Branch To Name, Comment\n",
    "required = ['Booking ID','Stock Out (ID)','Branch (ID)','Branch To (Name)','Comment']\n",
    "result['Booking ID'] = result['Booking ID'].str.replace('Booking-DHL ID : ','')\n",
    "result = pd.DataFrame(result[required])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID33_Headoffice.json\n"
     ]
    }
   ],
   "source": [
    "# 0 = ID33_Headoffice\n",
    "# 1 = ID33_insure\n",
    "# 2 = ID49\n",
    "# 3 = ID49_Tradein\n",
    "\n",
    "filedict = {0 : 'ID33_Headoffice', 1 : 'ID33_insure', 2 : 'ID49', 3 : 'ID49_Tradein'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_filedict = 3\n",
    "\n",
    "with open(f'{filedict.get(get_filedict)}.json','w+', encoding='utf-8',) as file:\n",
    "    result.to_json(file,orient='index',index=True, force_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import firebase_admin as fb\n",
    "from firebase_admin import firestore\n",
    "import pandas as pd\n",
    "\n",
    "cred = fb.credentials.Certificate(rf\"C:\\ITEC_Support\\my-work-python-script\\Database_in_pandas\\serviceAccount.json\")\n",
    "default_app = fb.initialize_app(cred)\n",
    "db = firestore.client()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.to_dict(orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgument",
     "evalue": "400 Document 'projects/itecdatabase-b286a/databases/(default)/documents/Data/ID:33_Insure' cannot be written because its size (1,137,672 bytes) exceeds the maximum allowed size of 1,048,576 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\google\\api_core\\grpc_helpers.py:50\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 50\u001b[0m     \u001b[39mreturn\u001b[39;00m callable_(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     51\u001b[0m \u001b[39mexcept\u001b[39;00m grpc\u001b[39m.\u001b[39mRpcError \u001b[39mas\u001b[39;00m exc:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\grpc\\_channel.py:946\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[1;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[0;32m    944\u001b[0m state, call, \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_blocking(request, timeout, metadata, credentials,\n\u001b[0;32m    945\u001b[0m                               wait_for_ready, compression)\n\u001b[1;32m--> 946\u001b[0m \u001b[39mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[39mFalse\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\grpc\\_channel.py:849\u001b[0m, in \u001b[0;36m_end_unary_response_blocking\u001b[1;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[0;32m    848\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 849\u001b[0m     \u001b[39mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[1;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.INVALID_ARGUMENT\n\tdetails = \"Document 'projects/itecdatabase-b286a/databases/(default)/documents/Data/ID:33_Insure' cannot be written because its size (1,137,672 bytes) exceeds the maximum allowed size of 1,048,576 bytes.\"\n\tdebug_error_string = \"{\"created\":\"@1662307565.254000000\",\"description\":\"Error received from peer ipv6:[2404:6800:4001:80a::200a]:443\",\"file\":\"src/core/lib/surface/call.cc\",\"file_line\":967,\"grpc_message\":\"Document 'projects/itecdatabase-b286a/databases/(default)/documents/Data/ID:33_Insure' cannot be written because its size (1,137,672 bytes) exceeds the maximum allowed size of 1,048,576 bytes.\",\"grpc_status\":3}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mInvalidArgument\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32mc:\\ITEC_Support\\my-work-python-script\\Database_in_pandas\\main.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/ITEC_Support/my-work-python-script/Database_in_pandas/main.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m my_doc_Ref \u001b[39m=\u001b[39m db\u001b[39m.\u001b[39mcollection(\u001b[39m\"\u001b[39m\u001b[39mData\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mdocument(\u001b[39m\"\u001b[39m\u001b[39mID:33_Insure\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/ITEC_Support/my-work-python-script/Database_in_pandas/main.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m my_doc_Ref\u001b[39m.\u001b[39;49mset(result)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\google\\cloud\\firestore_v1\\document.py:167\u001b[0m, in \u001b[0;36mDocumentReference.set\u001b[1;34m(self, document_data, merge, retry, timeout)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[39m\"\"\"Create / replace / merge a document in the Firestore database.\u001b[39;00m\n\u001b[0;32m    110\u001b[0m \n\u001b[0;32m    111\u001b[0m \u001b[39m- To \"upsert\" a document (create if it doesn't exist, replace completely\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[39m    result contains an ``update_time`` field.\u001b[39;00m\n\u001b[0;32m    165\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    166\u001b[0m batch, kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prep_set(document_data, merge, retry, timeout)\n\u001b[1;32m--> 167\u001b[0m write_results \u001b[39m=\u001b[39m batch\u001b[39m.\u001b[39mcommit(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    168\u001b[0m \u001b[39mreturn\u001b[39;00m _first_write_result(write_results)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\google\\cloud\\firestore_v1\\batch.py:59\u001b[0m, in \u001b[0;36mWriteBatch.commit\u001b[1;34m(self, retry, timeout)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[39m\"\"\"Commit the changes accumulated in this batch.\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \n\u001b[0;32m     45\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[39m    write result contains an ``update_time`` field.\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     57\u001b[0m request, kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prep_commit(retry, timeout)\n\u001b[1;32m---> 59\u001b[0m commit_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_client\u001b[39m.\u001b[39m_firestore_api\u001b[39m.\u001b[39mcommit(\n\u001b[0;32m     60\u001b[0m     request\u001b[39m=\u001b[39mrequest,\n\u001b[0;32m     61\u001b[0m     metadata\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_client\u001b[39m.\u001b[39m_rpc_metadata,\n\u001b[0;32m     62\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m     63\u001b[0m )\n\u001b[0;32m     65\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_write_pbs \u001b[39m=\u001b[39m []\n\u001b[0;32m     66\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite_results \u001b[39m=\u001b[39m results \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(commit_response\u001b[39m.\u001b[39mwrite_results)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\google\\cloud\\firestore_v1\\services\\firestore\\client.py:1067\u001b[0m, in \u001b[0;36mFirestoreClient.commit\u001b[1;34m(self, request, database, writes, retry, timeout, metadata)\u001b[0m\n\u001b[0;32m   1062\u001b[0m metadata \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(metadata) \u001b[39m+\u001b[39m (\n\u001b[0;32m   1063\u001b[0m     gapic_v1\u001b[39m.\u001b[39mrouting_header\u001b[39m.\u001b[39mto_grpc_metadata(((\u001b[39m\"\u001b[39m\u001b[39mdatabase\u001b[39m\u001b[39m\"\u001b[39m, request\u001b[39m.\u001b[39mdatabase),)),\n\u001b[0;32m   1064\u001b[0m )\n\u001b[0;32m   1066\u001b[0m \u001b[39m# Send the request.\u001b[39;00m\n\u001b[1;32m-> 1067\u001b[0m response \u001b[39m=\u001b[39m rpc(\n\u001b[0;32m   1068\u001b[0m     request,\n\u001b[0;32m   1069\u001b[0m     retry\u001b[39m=\u001b[39;49mretry,\n\u001b[0;32m   1070\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m   1071\u001b[0m     metadata\u001b[39m=\u001b[39;49mmetadata,\n\u001b[0;32m   1072\u001b[0m )\n\u001b[0;32m   1074\u001b[0m \u001b[39m# Done; return the response.\u001b[39;00m\n\u001b[0;32m   1075\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\google\\api_core\\gapic_v1\\method.py:154\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[1;34m(self, timeout, retry, *args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     metadata\u001b[39m.\u001b[39mextend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata)\n\u001b[0;32m    152\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mmetadata\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m metadata\n\u001b[1;32m--> 154\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped_func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\google\\api_core\\retry.py:283\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    279\u001b[0m target \u001b[39m=\u001b[39m functools\u001b[39m.\u001b[39mpartial(func, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    280\u001b[0m sleep_generator \u001b[39m=\u001b[39m exponential_sleep_generator(\n\u001b[0;32m    281\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initial, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maximum, multiplier\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_multiplier\n\u001b[0;32m    282\u001b[0m )\n\u001b[1;32m--> 283\u001b[0m \u001b[39mreturn\u001b[39;00m retry_target(\n\u001b[0;32m    284\u001b[0m     target,\n\u001b[0;32m    285\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predicate,\n\u001b[0;32m    286\u001b[0m     sleep_generator,\n\u001b[0;32m    287\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_deadline,\n\u001b[0;32m    288\u001b[0m     on_error\u001b[39m=\u001b[39;49mon_error,\n\u001b[0;32m    289\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\google\\api_core\\retry.py:190\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, deadline, on_error)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[39mfor\u001b[39;00m sleep \u001b[39min\u001b[39;00m sleep_generator:\n\u001b[0;32m    189\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 190\u001b[0m         \u001b[39mreturn\u001b[39;00m target()\n\u001b[0;32m    192\u001b[0m     \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m    193\u001b[0m     \u001b[39m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[0;32m    194\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\google\\api_core\\grpc_helpers.py:52\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[39mreturn\u001b[39;00m callable_(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     51\u001b[0m \u001b[39mexcept\u001b[39;00m grpc\u001b[39m.\u001b[39mRpcError \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m---> 52\u001b[0m     \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mfrom_grpc_error(exc) \u001b[39mfrom\u001b[39;00m \u001b[39mexc\u001b[39;00m\n",
      "\u001b[1;31mInvalidArgument\u001b[0m: 400 Document 'projects/itecdatabase-b286a/databases/(default)/documents/Data/ID:33_Insure' cannot be written because its size (1,137,672 bytes) exceeds the maximum allowed size of 1,048,576 bytes."
     ]
    }
   ],
   "source": [
    "my_doc_Ref = db.collection(\"Data\").document(\"ID:33_Insure\")\n",
    "my_doc_Ref.set(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bda2d7e1d8ce3e9d9eb4845ce2bf2d2cd8b95573ee5d31a32a74e85678cbafe3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
